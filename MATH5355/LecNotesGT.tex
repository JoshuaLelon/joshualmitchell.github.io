% Thank you Josh Davis for this template!
% https://github.com/jdavis/latex-homework-template/blob/master/homework.tex

\documentclass{article}

\newcommand{\hmwkTitle}{Lecture Notes}

% \input{ShortcutsGraphTheory}

% ----------

% Packages

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{chngcntr}
\usepackage{blkarray}
% Libraries

\usetikzlibrary{automata, positioning, arrows}

\graphicspath{{/Users/jm/iclouddrive/5355pics/}}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{}
\rhead{\hmwkClass\ (\hmwkClassInstructor): \hmwkTitle}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}
\setcounter{secnumdepth}{0}

\newcommand{\hmwkClass}{MATH 5355 / Graph Theory}        % Class
\newcommand{\hmwkClassInstructor}{Dr. Shen}           % Instructor
\newcommand{\hmwkAuthorName}{\textbf{Joshua Mitchell}} % Author

%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small\vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
    \vspace{3in}
}

\author{\hmwkAuthorName}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

%
% Various Helper Commands
%

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}


% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}

% Formatting commands:

\newcommand{\mt}[1]{\ensuremath{#1}}
\newcommand{\nm}[1]{\textrm{#1}}

\newcommand\bsc[2][\DefaultOpt]{%
  \def\DefaultOpt{#2}%
  \section[#1]{#2}%
}
\newcommand\ssc[2][\DefaultOpt]{%
  \def\DefaultOpt{#2}%
  \subsection[#1]{#2}%
}
\newcommand{\bgpf}{\begin{proof} $ $\newline}

\newcommand{\bgeq}{\begin{equation*}}
\newcommand{\eeq}{\end{equation*}}	

\newcommand{\balist}{\begin{enumerate}[label=\alph*.]}
\newcommand{\elist}{\end{enumerate}}

\newcommand{\bilist}{\begin{enumerate}[label=\roman*)]}	

\newcommand{\bgsp}{\begin{split}}
% \newcommand{\esp}{\end{split}} % doesn't work for some reason.

\newcommand\prs[1]{~~~\textbf{(#1)}}

\newcommand{\lt}[1]{\textbf{Let: } #1}
     							   %  if you're setting it to be true
\newcommand{\supp}[1]{\textbf{Suppose: } #1}
     							   %  Suppose (if it'll end up false)
\newcommand{\wts}[1]{\textbf{Want to show: } #1}
     							   %  Want to show
\newcommand{\as}[1]{\textbf{Assume: } #1}
     							   %  if you think it follows from truth
\newcommand{\bpth}[1]{\textbf{(#1)}}

\newcommand{\step}[2]{\begin{equation}\tag{#2}#1\end{equation}}
\newcommand{\epf}{\end{proof}}

\newcommand{\dbs}[3]{\mt{#1_{#2_#3}}}

\newcommand{\sidenote}[1]{-----------------------------------------------------------------Side Note----------------------------------------------------------------
#1 \

---------------------------------------------------------------------------------------------------------------------------------------------}

% Analysis / Logical commands:

\newcommand{\br}{\mt{\mathbb{R}} }       % |R
\newcommand{\bq}{\mt{\mathbb{Q}} }       % |Q
\newcommand{\bn}{\mt{\mathbb{N}} }       % |N
\newcommand{\bc}{\mt{\mathbb{C}} }       % |C
\newcommand{\bz}{\mt{\mathbb{Z}} }       % |Z

\newcommand{\ep}{\mt{\epsilon} }         % epsilon
\newcommand{\fa}{\mt{\forall} }          % for all
\newcommand{\afa}{\mt{\alpha} }
\newcommand{\bta}{\mt{\beta} }
\newcommand{\mem}{\mt{\in} }
\newcommand{\exs}{\mt{\exists} }

\newcommand{\es}{\mt{\emptyset} }        % empty set
\newcommand{\sbs}{\mt{\subset} }         % subset of
\newcommand{\fs}[2]{\{\uw{#1}{1}, \uw{#1}{2}, ... \uw{#1}{#2}\}}

\newcommand{\lra}{ \mt{\longrightarrow} } % implies ----->
\newcommand{\rar}{ \mt{\Rightarrow} }     % implies -->

\newcommand{\lla}{ \mt{\longleftarrow} }  % implies <-----
\newcommand{\lar}{ \mt{\Leftarrow} }      % implies <--

\newcommand{\av}[1]{\mt{|}#1\mt{|}}  % absolute value

\newcommand{\prn}[1]{(#1)}
\newcommand{\bk}[1]{\{#1\}}

\newcommand{\ps}{\mt{\operatorname{+}} }
\newcommand{\ms}{\mt{\operatorname{-}} }

\newcommand{\ls}{\mt{\operatorname{<}} }
\newcommand{\gr}{\mt{\operatorname{>}} }

\newcommand{\lse}{\mt{\operatorname{\leq}} }
\newcommand{\gre}{\mt{\operatorname{\geq}} }

\newcommand{\eql}{ \mt{\operatorname{=}} }

\newcommand{\pr}{\mt{^\prime}} 		   % prime (i.e. R')
\newcommand{\uw}[2]{#1\mt{_{#2}}}
\newcommand{\uf}[2]{#1\mt{^{#2}}}
\newcommand{\frc}[2]{\mt{\frac{#1}{#2}}}
\newcommand{\lmti}[1]{\mt{\displaystyle{\lim_{#1 \to \infty}}}}
\newcommand{\limt}[2]{\mt{\displaystyle{\lim_{#1 \to #2}}}}

\newcommand{\bnm}[2]{\mt{#1\setminus{#2}}}
\newcommand{\bnt}[2]{\mt{\textrm{#1}\setminus{\textrm{#2}}}}
\newcommand{\bi}{\bnm{\mathbb{R}}{\mathbb{Q}}}

\newcommand{\urng}[2]{\mt{\bigcup_{#1}^{#2}}}
\newcommand{\nrng}[2]{\mt{\bigcap_{#1}^{#2}}}
\newcommand{\nck}[2]{\mt{{#1 \choose #2}}}

\newcommand{\nbho}[3]{\textrm{N(}#1, #2\textrm{) }\cap \textrm{ #3} \neq \emptyset}
     							   %  N(x, eps) intersect S \= emptyset
\newcommand{\nbhe}[3]{\textrm{N(}#1, #2\textrm{) }\cap \textrm{ #3} = \emptyset}
     							   %  N(x, eps) intersect S  = emptyset
\newcommand{\dnbho}[3]{\textrm{N*(}#1, #2\textrm{) }\cap \textrm{ #3} \neq \emptyset}
     							   %  N*(x, eps) intersect S \= emptyset
\newcommand{\dnbhe}[3]{\textrm{N*(}#1, #2\textrm{) }\cap \textrm{ #3} = \emptyset}
     							   %  N*(x, eps) intersect S = emptyset
     							   
\newcommand{\eqn}[1]{\[#1\]}

\newcommand{\txt}[1]{\text{#1}} % Not new command, but remember \text for text in eqns
\newcommand{\tl}{\mt{\thicksim}}
\newcommand{\mn}[1]{\mt{\overline{#1}}}
\newcommand{\sg}{\mt{\sigma}}
\newcommand{\ssq}{\mt{\sigma^2}}	

\newcommand{\bh}[1]{\mathbf{\hat{\text{$#1$}}}}
\newcommand{\bth}{\mt{\bh{\beta}}}
\newcommand{\yh}{\mt{\bh{Y}}}

\newcommand{\exv}[1]{E[#1]}
\newcommand{\vrn}[1]{V[#1]}

\newcommand{\gv}{ \mt{|} }

\newcommand{\cov}[2]{\txt{Cov(#1, #2)}}

\newcommand{\img}[1]{
\begin{figure}[h]
  \includegraphics[width=0.5\linewidth]{#1}
\end{figure}
}
\newcommand\tab[1][1cm]{\hspace*{#1}}	
\newcommand{\sumin}[1]{\mt{\sum_{i = 1}^n #1}}

\newcommand{\brm}[1]{\begin{pmatrix} #1 \end{pmatrix}}

\newcommand{\inm}[1]{\mt{\left\[ \begin{smallmatrix} #1 \end{smallmatrix} \right\]}}

\newcommand{\lbm}[4]{
	  \begin{blockarray}{#1} % a c for every row, plus the c-labels
        #2 \\ % & c-label1 & c-label2 & c-label3...
      \begin{block}{c(#3)} % a c for every column only
        #4 % r-label1 & data & data & data ... \\
           % r-label2 & data & data & data ... \\
           % ...
           % r-labeln & data & data & data ... \\
      \end{block}
    \end{blockarray}
}

% Example:
% \[\lbm{ccccc}{& H & y & d}{cccc}{H & 4 & 4 & 4 \\
% Y & 3 & 3 & 3 \\
% D & 2 & 2 & 2 \\
% D & 2 & 2 & 2 \\}\]

\newcommand{\unds}[2]{\mt{\underset{#1}{#2}}} % stuff underneath!
	 
% ----------

\begin{document}

An excellent resource for Graph Theory powerpoint slides:

http://people.qc.cuny.edu/faculty/christopher.hanusa/courses/634sp11/Documents/Forms/AllItems.aspx

\bsc{Notes Packet 1}{

\ssc{Graph Definition} {
Figure n1.1

A graph G \eql (V, E, f)

V is the vertex set (e.g. w, x, y...)

E is the edge set (e.g. \uw{e}{1}, \uw{e}{2}...)

f is the function mapping edges to vertices (i.e. f: \uw{e}{1} \lra xw, \uw{e}{2} \lra xw, \uw{e}{3} \lra yw ...)
}
\ssc{Simple Graph Definition}{
A \textbf{simple graph} G (aside from the null graph) is a graph with n \gre 1 vertices and m \gre 0 edges that consists of a vertex set

V(G) \eql \bk{\uw{v}{1}, \uw{v}{2}... \uw{v}{n}}

and an edge set

E(G) \eql \bk{\uw{e}{1}, \uw{e}{2}... \uw{e}{m}}

where each edge is an unordered pair of vertices.
}

An example graph theory problem: Can x workers do y jobs such that all of the jobs can be done by at least one worker?

Here's a table of workers and the corresponding jobs they can do.

\begin{tabular}{l|c}
  Worker \# & Job \\
  \hline
  1 & a\\
  2 & a, b\\
  3 & b, c, d\\
  4 & a, b
\end{tabular}

Here's a graph of what that might look like:

Figure n1.3

If we look at jobs c and d, we notice that both can only be done by worker \#3.

Figure n1.4

\ssc{Subgraph Definition}{

A \textbf{subgraph} of a graph G is a graph H such that V(H) \sbs V(G) and E(H) \sbs E(G).

We write this as H \sbs G
}
}

\bsc{Notes Packet 2}{

A \textbf{path} is a sequence of unique edges that connects a sequence of unique vertices. You can't repeat any vertices or edges, but the path doesn't have to contain all the edges or vertices from the graph.

A \textbf{cycle} is a path that, instead of its endpoint being another unique vertex, it ends at its beginning vertex. Both vertices and edges are not allowed to be repeated here as well.

A graph is \textbf{connected} if, given any two vertices a and b, there is a path between a and b.

A \textbf{simple} graph G is a graph such that G has no \textbf{loops} (an edge such that its two endpoints are the same vertex), and, given any two vertices a and b, a and b have no more than one edge between them.

A \textbf{loopless} graph G has all the qualities of a simple graph, but allows any two vertices to have more than one edge between them.

The \textbf{Adjacency Matrix} of a graph G, A(G), is a matrix whose entries are the number of edges between two vertices. It is symmetric if the graph is undirected.

The \textbf{Incidence Matrix} of a graph G, M(G), is a matrix whose entries indicate whether a vertex and an edge are \textbf{incident} (i.e. touching or connected). The number of rows doesn't necessarily equal the number of columns (i.e. \av{E(G)} \eql \av{V(G)} can be true or false).

For example, here is a loopless graph G:

Figure n2.2

And here is A(G) and M(G):

Example:
\[\underset{\textrm{A(G) - Adjacency Matrix of G}}{\lbm{ccccc}{
  & w & x & y & z}{cccc}
{w & 0 & 1 & 1 & 0 \\
 x & 1 & 0 & 2 & 0 \\
 y & 1 & 2 & 0 & 1 \\
 z & 0 & 0 & 1 & 0 \\}}
 \tab
Figure-n2.2
 \tab
\underset{\textrm{M(G) - Incidence Matrix of G}}{\lbm{cccccc}{
 & a & b & c & d & e}{ccccc}{
 w & 1 & 1 & 0 & 0 & 0 \\
 x & 1 & 0 & 1 & 1 & 0 \\
 y & 0 & 1 & 1 & 1 & 1 \\
 z & 0 & 0 & 0 & 0 & 1 \\}}\]

The \textbf{degree} of a vertex x, d(x), is how many edges are incident (connected to) x.

A(G) and M(G) are related like so:

\eqn{\textrm{A(G)} + \lbm{ccccc}{
  &  &  &  & }{cccc}
{ & d(w) &  &  &  \\
  &  & d(x) &  &  \\
  &  &  & d(y) &  \\
  &  &  &  & d(z) \\} = MM^T}
}

Edges can also cross one another. From most perspectives, \uw{G}{1} and \uw{G}{2} are the same graph.

Figure n2.4, Figure n2.5

In fact, \uw{G}{1} and \uw{G}{2} are \textbf{isomorphic}.

f: V(\uw{G}{1}) \lra V(\uw{G}{2})

1 \lra a

2 \lra b

...

5 \lra e

ij \mem E(\uw{G}{1} iff f(i)f(j) \mem E(\uw{G}{2})

The full definition is this:

An \textbf{isomorphism} from G to H is a \textbf{bijection} (a 1 to 1 correspondence) f: V(G) \lra V(H) such that

given an edge uv, uv \mem E(G) iff f(u)f(v) \mem E(H)

We say G $\cong$ H to indicate that G is isomorphic to H.

The \textbf{compliment} of a graph G, notated as $\bar G$, is a graph with the same vertex set as G, but if uv \mem E(G), then uv $\not\in$ E($\bar G$) and vise versa.

G $\cong$ H iff $\bar G$ $\cong$ $\bar H$

\ssc{Bipartite Graph Definition}{

A \textbf{bipartite graph} G, also called a \textbf{bigraph}, is a graph st V(G) can be decomposed into two \textbf{disjoint} sets (i.e. any vertex v \mem V(G) is either in one set or the other, not both) such that no two vertices within the same set are \textbf{adjacent} (connected by an edge). A bipartite graph is a special case of a \textbf{k-partite} graph with k\eql 2.

}

Some other vocabularly:

A \textbf{complete} graph, \uw{K}{n}, is a simple graph with n vertices such that there is one edge between any two vertices.

The number of edges in \uw{K}{n}, \av{E(\uw{K}{n})}, is equal to \nck{n}{2}. Mathematically,

\eqn{|\textrm{E(\uw{K}{n})}| = \frac{n(n - 1)}{2} = \nck{n}{2}}

\textbf{\uw{C}{n}} is shorthand for a cycle with n vertices.

\textbf{\uw{P}{n}} is shorthand for a path with n vertices and n \ms 1 edges.

\textbf{\uw{K}{r, s}} is shorthand for a complete, bipartite graph such that the independent sets have r and s vertices, respectively.

The notation \uw{K}{5} \ms \bk{e} means a complete graph with 5 vertices minus an edge e.

\ssc{Decomposition}{

A \textbf{decomposition} of a graph G is a set of subgraphs \uw{H}{1}, \uw{H}{2}, ... \uw{H}{k} that partition the edges of G.

That is, \fa i, j,

\eqn{\bigcup_{1\lse i\lse k}\uw{H}{i} = G,\tab E(H_i) \cap E(H_j) = \es}

An \textbf{H-decomposition} is a decomposition of G such that each subgraph \uw{H}{i} in the decomposition is \textbf{isomorphic} to H.

For example, we know that \uw{K}{5} \ms \bk{e} decomposes into 3\uw{P}{4} (3 paths with 4 vertices):

Figure 2.6

Can \uw{K}{6} decompose into 5\uw{P}{4}?

Yes. Using the "rotation" trick.

Figure 2.7

How many copies of \uw{P}{4} can \uw{K}{8} decompose into?

So, \uw{K}{8} has \frc{8(8 - 1)}{2} \eql 23 edges.

However, \uw{P}{4} has 4 vertices, and therefore 3 edges.

There is no integer k such that k\uw{P}{4} \eql 23, so the answer is: it can't.
}

\ssc{Peterson Graph Definition}{

A \textbf{Peterson graph} G is a graph with

V(G) \eql \bk{A : A \sbs \bk{1, 2, 3, 4, 5}, and \av{A} \eql 2}

and

AB \mem E iff A $\cap$ B \eql \es

In other words, if the vertex is named 34, then it can only be connected to vertices that have neither 3 nor 4 in the name (i.e. 51, 52, 12)

Example:

Figure N2.8

}

\newpage

\bsc{Notes Packet 3}{
\ssc{Induction Example}{
P(n) is true for every positive integer n.

Step \bpth{1}: P(1) is true (should be a trivial case).

Step \bpth{2}: Assume that, \fa k \gre 1, P(n) is true for n\eql k

Step \bpth{3}: Prove that if P(n) is true for n\eql k, then P(n) is true for n\eql k \ps 1 (this is "weak" induction)

Step \bpth{4}: This proves that since P(1) is true, P(2) is true. Since P(2) is true, P(3) is true. And so on...
}

\

A \textbf{walk} is a sequence of edges and vertices in a graph (i.e. a path with no restrictions, so you can cross over the same edge and/or vertex more than once).

A \textbf{trail} is a walk with no repeated edges. Repeated vertices are still okay.

A \textbf{path} is, again, a sequence of connected edges and vertices in a graph such that there are no repeated edges nor vertices.

A \textbf{circuit} is a cycle that allows repeated vertices. No repeated edges still, though. Also known as a \textbf{closed trail}.

A \textbf{cycle} is a path that begins and ends at the same vertex. Also known as a \textbf{closed path}.

A \textbf{u, v walk / trail / path} is a walk / trail / path that begins at u and ends at v.

In the above definition for u, v walk / trail / path, u and v would be the \textbf{endpoints}.

The \textbf{internal vertices} are the vertices that aren't endpoints.

The \textbf{length} of a walk / trail / path / circuit / cycle is how many edges it has. 

\

\ssc{Lemma 1.2.5}{

Every u, v walk contains a u, v path.

\bgpf
Insert proof here.

Figure N3.1
\epf

Be careful, though. If you have a u, v path and a v, w path, that doesn't mean you have a u, w path containing both a u, v path and a v, w path (they might not necessarily be head to tail).

}

\ssc{Connected / Disconnected Graphs}{
A graph is \textbf{connected} if there is a path between any two vertices. It is \textbf{disconnected} \exs a vertex such that that's not the case.

If G is disconnected, then we can think of G as a set of components.

A component is \textbf{non-trivial} if it has at least one edge.

Adding an edge can either decrease the number of components, c(G), or not change it.

Deleting an edge can either increase c(G) or not change it.

Deleting a vertex (which also deletes the attached edges) can increase c(G) by n where 0 \lse n \lse $\infty$.
}

\ssc{Proposition 1.2.11}{
If you have a graph with n vertices and k edges, then c(G) \gre n \ms k
}

An edge is \textbf{cut-edge} if removing the edge increases c(G) (i.e. the edge is a "bridge").

A vertex is a \textbf{cut-vertex} if removing the vertex increases c(G).

An \textbf{induced subgraph} of G is a subgraph H \sbs G such that if e \mem E(G) and e's endpoints are both members of V(H), then e \mem E(H). (i.e. G[T] where T \sbs V)

\ssc{Theorem 1.2.14}{
e is a cut-edge iff e belongs to no cycle

INSERT FULL PROOF HERE
\bgpf
\lra 

\lla
By contrapositive: e is not a cut-edge \lra e belongs to a cycle
\epf

Recall: Bipartite graphs

Figure n3.2

}

\ssc{Theorem 1.2.17}{
A graph G is bipartite iff there are no odd cycles.

INSERT FULL PROOF
\bgpf 
\lra 

\lla
If there is no odd cycle then every walk is odd.
Any closed walk can be decomposed into cycles.
\epf 

To prove G is bipartite, find a bipartition X and Y.

To prove G is not bipartite, find an odd cycle.

To test if G is bipartite or not uses an algorithm of O(\av{E[G]})
}

\ssc{Eulerian Graph Definition}{

A \textbf{Eulerian} graph G is a graph containing a Eulerian circuit. It can also mean a graph such that every vertex is of even degree. These definitions coincide for connected graphs.

A \textbf{Eulerian Circuit} is a circuit containing all the edges of a graph.

In other words, if a graph is connected and every vertex has even degree, then it has at least one Eulerian Circuit. 

If a graph has more than 2 vertices of odd degree, then it cannot have a Eulerian Circuit or Eulerian Path.

If a graph is connected and has exactly 2 vertices of odd degree, then it has at least one Eulerian Circuit.

}

An \textbf{even} graph G is a graph such that \fa v \mem V(G), deg(v) is even.

\textbf{Lemma:} If \fa v \mem V(G), deg(v) \gre 2, then G contains a cycle.

The \textbf{maximum} path is the path with the largest number of edges (if there's a tie there is no maximum path).

A \textbf{maximal} path is a path such that it is contained by no larger path.

\ssc{Theorem 1.2.26}{

A graph G is Eulerian iff c(G) \lse 1 and G is an even graph
\lra 


\lla 

Induction on \av{E} \eql m

}

\ssc{Application 2.3.10 - The Chinese Postman Problem}{

Pictures, maybe?

Something about weighted \uw{K}{8}...

Something about the Hungarian theorem/algorithm

Find the minimum total weight of 4 edges that pair up the 8 vertices.

2nd to last page of packet 3, there's some pictures that maybe go here

}

\ssc{Proof Technique: Extremality}{

Proposition 1.2.28: if, \fa v \mem V(G), d(v) \gre k, then \exs a path of length k.

There's some other stuff, but some is repeats (maximum, maximal...)

}



}

\newpage

\sidenote{END OF NOTES FROM BEFORE TEST 1, BEGINNING OF POST TEST 1 NOTES}

Definition of a king:

For any x, either King \lra x, or King \lra y \lra x for some path y.

Prop 1.4.30 - Every tournament has a king

-----

A graph is \textbf{acyclic} if it has no cycle.

A graph is a \textbf{forest} if it is acyclic.

A graph is a \textbf{tree} if it is a connected acyclic graph.

<pictures of trees>

A \textbf{leaf} is a pendant vertex (i.e. a vertex with degree 1)

A \textbf{star} is \textbf{***}

<picture of a star>

The \textbf{distance}, d(u, v), is the length of the shortest path between two vertices u and v.

\ssc{Lemma 2.1.3:}{
Every tree G st \av{V(G)} \gre 2 has \gre 2 leaves.

Deleting a leaf results in a smaller tree on n \ms 1 vertices.

\bgpf

<picture of maximal path. i.e. dot-dot-dot-dot>

No leaf is an internal vertex of a path.

We would use an induction method to prove this:

B \textbf{***}  A(n) \rar B(n)

A(n): T is a tree on n vertices

B(n): T has n \ms 1 edges

\wts{num edges \eql num vertices - 1}

<picture from top right of Method of Induction page>

Induction on n:

Step 1: 

T\pr \eql T \ms \bk{a leaf}

T\pr is a tree on n \ms 1 vertex

Step 2:

T\pr has n \ms 2 edges (induction hypothesis)

Step 3:

T \eql T\pr \ps \bk{an edge}

T has n \ms 2 \ps 1 \eql n \ms 1 edges.

\epf

} 

\bsc{Theorem 2.1.A (or 4?)}{

\balist
\item connected, no cycle. n vertices (do I have n \ms 1 edges?)
\item connected, n \ms 1 edges
\item n \ms 1 edges, no cycle (not sure if connected)
\item For any u, v \mem V, \exs exactly one u, v \ms path. No loops.
\elist

\bgpf

We're going to say these three things are equivalent.

We did A \rar B in previous slides. (induction on n)

For B \rar C:

\wts{G has no cycles}

Suppose G has cycles (contradiction):

<picture from Theorem 2.1.A (or 4)

G\pr \eql G \ms \bk{\uw{e}{1}, \uw{e}{2}, ...} is acyclic

acyclic, connected, n \ms 1 vertices \eql tree 

G\pr is connected, (using any tree that has n vertices has n \ms 1 edges), G\pr has n \ms 1 edges

C \rar A (if you have 3 and 2, then prove you have 1):

Suppose c(G) (number of components) \eql k (by contradiction).

<pictures of \uw{n}{1} vertices, \uw{n}{2} vertices.. \uw{n}{k} vertices>
<has \uw{n}{1} \ms 1 edges, \uw{n}{2} \ms 1 edges, etc...>

\eqn{n - 1 = e(G) = \sum_{i = 1}^k (\uw{n}{1} - 1) = \sum_{i = 1}^k (\uw{n}{i} - k) = n - k}

The only solution is that k \eql 1.

\epf

}

\ssc{Corollary 2.1.5}{

\balist
\item Every edge of a tree is a cut-edge.
\item Adding one edge to a tree forms exactly one cycle.
\item Every connected graph contains a spanning tree.
\elist

}

A spanning subgraph of G is a subgraph of G that contains all the vertices of G.

A spanning tree is a spanning subgraph that is a tree.

\ssc{Proposition 2.1.8 (or B)}{

Tree T has k edges, simple graph G has min(G) \gre k (minimum degree bigger than or equal to k) \lra T is a subgraph of G.

T\pr \eql T \ms \bk{a leaf} has k \ms 1 edges.

<picture of G>

To prove this, we would use induction on k.

min vertex(G) \gre k \gre k \ms 1

T\pr has k vertices.

Base: k \eql 1

If T has only 2 vertices, then T has 1 edge. This is a trivial case.

}

<Missing some other stuff>

\ssc{Definition 2.1.9}{

eccentricity (for any connected graph) \ep(u) \eql max\bk{d(u, v) : v \mem V(G)}

<picture below eccentricity> (where 4 is the radius, 7 is the diameter)

The radius, rad(G), is the minimum \textbf{***} \eql min of \ep(u) where u \mem V

The diameter, diam(G), is the maximum \textbf{***} \eql max of \ep(u) where u \mem V

\ep(u) \eql d(u, v) for some leaf v

}

\ssc{Theorem 2.1.13 (Jordan, 1869)}{

The center of a tree is always one edge or one vertex.

\bgpf

We do induction on n.

\lt{T\pr \eql T \ms \bk{all leaves}}

\uw{\ep}{T\pr}(u) \eql \uw{\ep}{T}(u) \ms 1

If G $\neq$ a line segment with a vertex at each end, then no leaf can be a center vertex.

\epf

}

\ssc{Theorem 2.1.10 [Not On Test]}{
Not on test
}

\ssc{Theorem 2.1.11}{
G is simple, Diam(G) \gre 3 \lra Diam(\mn{G}) \lse 3

\bgpf

% u ._._._. v d(u, v) \eql 3

% Extra credit opportunity: Can you prove it's true for any n? Not just 3? How about 2 and 4 or vise versa? Or something else?

Claim: x cannot be adjacent to both u and v, otherwise distance will be smaller than 3. So, at least one of them is not true.

Dotted lines signify non-adjacency.

In the case of neither x nor y being adjacent to u, then in \mn{G}, u is adjacent to both x and y.

In the case 

\epf
}

\ssc{hi}{

How many simple graphs with vertex set [n] are there?

[n] \eql \bk{1, 2, 3, ... n}

In other words, how many labelled graphs on n vertices are there?

Answer: \uf{2}{\nck{n}{2}}

How many trees with vertex set [n] are there?

Cayley's formula: \uf{n}{n - 2} (proof is very complicated, only need to understand conclusion) (the number of labelled trees on n vertices)

Labelled trees: 1:1 (\uw{a}{1}, \uw{a}{2}, ... \uw{a}{n - 2}) : \uw{a}{i} \mem [n]

Suppose I have 3 vertices. How many labeled trees can I get?

Answer: 3 possible labeled trees. If you have vertices 1, 2, and 3, then you can have 3 graphs: \bpth{1} 12, 23, \bpth{2} 23, 31, \bpth{3} 31, 12

Let's say I have a complete graph, \uw{K}{n}, with labelled vertices. How many labelled spanning trees does it have? Answer: \uf{n}{n - 2} (Cayley's formula)

To generalize the problem:

Contraction of edge:

<picture with edge uv and vertices A, B, C \lra picture with multiple edges between w and each vertex in C>

Example 2.2.9:

<picture of a square with a diagonal edge, same picture minus diagonal edge (G \ms e), bird (G dot e))

Proposition 2.2.8

$\tau$(G) (the number of spanning trees of G) \eql $\tau$(G \ms e) \ps $\tau$(G dot e)

\lt{T be a spanning tree of G}
 
 case i: e (the diagonal edge in the picture) is not in E(T)
 
 Any spanning tree of the original graph without using the diagonal is still a spanning tree. If you don't use the diagonal edge, it's from G \ms e.
 
 case ii: e (the diagonal edge in the picture) is in E(T)
 
 You should prove Prop 2.2.8 for practice.
 
 Remark 2.2.10 (Basis case for computing $\tau$(G))

Suppose G has no cycle other than multiple edges. Then:

$\tau$(G) \eql \bk{product of edge multiplicities if G is connected, 0 if disconnected}

<Remark picture>

1 * 2 * 3 choices

You're encouraged to try an example. For example: \uw{K}{4}

For a general graph, the Cayley formula doesn't work. Here's a 3rd way:

Theorem 2.2.12

\lt{G be a loopless n-graph (graph with n vertices)}

Q \eql \prn{\uw{q}{ij}}$_{n\times n}$ is defined by:

\uw{q}{ij} \eql \bk{d(\uw{v}{i}) if i \eql j, $-a_{ij}$ if i $\neq$ j}

\uw{a}{ij} : the number of edges joining \uw{v}{i} and \uw{v}{j}

\uf{Q}{*} : obtained by deleting any row s and column t of Q.

Then $\tau$(G) \eql $(-1)^{s + t}$ det \uf{Q}{*}

<picture 3>

The sum of every row and every column is equal to 0. Why?

The diagonal talks about the degree, but the off diagonal takes off each edge.

Determining the determinant of the matrix Q doesn't give you any new information, but deleting any row or column and making a submatrix, \uw{Q}{*}, of the matrix, and then taking the determinant will.

The absolute value of det \uw{Q}{*} (or just multiplying by $(-1)^{s + t}$ will give you $\tau$(G)

(we took both a row (1st row) and a column (1st column) to make it symmetric and make it easier to take the determinant)

\ssc{Conjecture 2.2.13 (still open)}{

\uw{K}{2m + 1} decomposes into 2m \ps 1 copies of T with m edges.

So \uw{K}{2m + 1} has \frc{(2m + 1)(2m)}{2} edges

Therefore, there are 2m \ps 1 copies of T.

}

Graceful labeling: a 1-1 correspondence between the vertices and a set of numbers for each vertex (packed very closely from 0 to n \ms 1 (where n is the number of vertices))

f: V \lra distinct number \mem \bk{0, 1, ... m} (a bijection from a vertex set to "this" set)

For example. If T has m edges, how many vertices do you have? Answer: m \ps 1

You want every vertex to have a distinct number.

<graceful labelling picture>

f(uv): \eql \av{f(u) \ms f(v)}

\bk{f(u, v): uv \mem E} \eql \bk{1, 2, ... m}

\ssc{Conjecture 2.2.15: The Graceful Tree Conjecture (Kotzig, Ringel, 1964)}{
Open, stronger than conjecture 2.2.13.

Every tree has a graceful labeling. 

}

\ssc{Theorem 2.2.16}{
T is graceful \rar Conjecture 2.2.13 holds

<picture 1, picture 2 - examples of this>

Remember, we want all edges to receive different numbers (Graceful labelling), so when we do a rotation, all of the different edges are covered exactly once

displacement(i, j): number of unit moves from i to j

\uw{K}{2m + 1} 
}

end of 10/11 lecture

beginning of 10/16 lecture

\ssc{Caterpillar (special type of tree)}{

Example of a caterpillar tree:

Figure n6.1

Any caterpillar is graceful.

Figure n6.2

}

\ssc{Theorem 2.2.19}{

T is a caterpillar iff T has no component like this:

Figure n6.3

\bgpf

T\pr = T \ms \bk{all leaves}

What is T\pr?

A path.

T is a caterpillar iff T\pr is a path

T has no Figure n6.3 iff T\pr has no Figure n6.4

NEED MORE PROOF

\epf

}

\ssc{Minimum Spanning Tree Problem}{

A super important problem in Graph Theory.

Suppose we have a really remote area. There are a few villages, with some distances between all of them. We know all of the distance between any two villages.

A spanning tree is the most efficient structure in the sense that it has the fewest (number of edges) while still being connected.

A \textbf{weighted graph} G is a graph s.t all the edges of G have nonnegative weights. In other words, for a graph G, there is a function W that maps all e \mem E(G) to nonnegative weights.

If G is the following graph:

Figure n6.5

What is the minimum weight of a path from x to y?

The running time to solve this is O(f(n), where

the number of computational steps \lse c\av{f(n)} for n \gre a

where c is a constant and n is the size of the input.

The \textbf{minimum spanning tree} is the tree of a graph that connects all the vertices of a graph with edges such that

\eqn{\sum_{e \mem T} W(e)}

is minimized.
}

\ssc{Example 2.3.2 - The Greedy Algorithm}{
\lt{G be the below graph}

Figure n6.6

\textbf{Algorithm 2.3.3}:

Set V(H) \eql V(G), E(H) \eql \es

If H is disconnected, add to H the cheapest edge (the edge with the smallest weight) joining two components of H.

}

}

10/18 Lecture





\end{document}